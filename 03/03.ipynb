{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# ECG\n",
    "Load data\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e6142749e34afa43"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "       0    1    2    3    4    5    6    7    8    9  ...  66   67   68  69  \\\n30   -52 -180  -68   59   72  162  210  286  356  350  ...  10   18    8  14   \n173  162  220  298  264  136   12   -2  -20  -16  -24  ... -46 -148 -178 -51   \n140  128  255  324  266  138   10   98  140  126  148  ...   6   -8   -2  -2   \n75     4  -66 -194 -154  -27    4  120  180  244  352  ...   8    6    8   0   \n60    26    8   80  -14  -24  -92 -106 -120 -114 -104  ...  40   86   58  50   \n..   ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ..  ...  ...  ..   \n151   58   86  148  275  338  278  150   22  -34  -12  ...   0    0    0   0   \n103  -58 -186 -108   19   10   78  126  184  282  274  ...  16   18   22  14   \n99   198  262  152   24  -86  -74  -68 -118  -64  -62  ...   0    0    0   0   \n116   -6  -14  -98  -98   29    2   64  126  182  252  ...   0    0    0   0   \n87    14  -90 -218  -96   31   48  146  208  278  368  ...  10    8    4   4   \n\n     70  71   72   73  74  label  \n30   10  10   12   10  12      0  \n173  -8  36    0    0   0      1  \n140  -4 -14   -6   -6 -10      1  \n75   10  18   26   32  34      0  \n60   76  98  100  102  94      0  \n..   ..  ..  ...  ...  ..    ...  \n151   0   0    0    0   0      1  \n103  18  18   12   18  22      1  \n99    0   0    0    0   0      0  \n116   0   0    0    0   0      1  \n87   18  22   28   36  26      0  \n\n[200 rows x 76 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>...</th>\n      <th>66</th>\n      <th>67</th>\n      <th>68</th>\n      <th>69</th>\n      <th>70</th>\n      <th>71</th>\n      <th>72</th>\n      <th>73</th>\n      <th>74</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>30</th>\n      <td>-52</td>\n      <td>-180</td>\n      <td>-68</td>\n      <td>59</td>\n      <td>72</td>\n      <td>162</td>\n      <td>210</td>\n      <td>286</td>\n      <td>356</td>\n      <td>350</td>\n      <td>...</td>\n      <td>10</td>\n      <td>18</td>\n      <td>8</td>\n      <td>14</td>\n      <td>10</td>\n      <td>10</td>\n      <td>12</td>\n      <td>10</td>\n      <td>12</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>173</th>\n      <td>162</td>\n      <td>220</td>\n      <td>298</td>\n      <td>264</td>\n      <td>136</td>\n      <td>12</td>\n      <td>-2</td>\n      <td>-20</td>\n      <td>-16</td>\n      <td>-24</td>\n      <td>...</td>\n      <td>-46</td>\n      <td>-148</td>\n      <td>-178</td>\n      <td>-51</td>\n      <td>-8</td>\n      <td>36</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>140</th>\n      <td>128</td>\n      <td>255</td>\n      <td>324</td>\n      <td>266</td>\n      <td>138</td>\n      <td>10</td>\n      <td>98</td>\n      <td>140</td>\n      <td>126</td>\n      <td>148</td>\n      <td>...</td>\n      <td>6</td>\n      <td>-8</td>\n      <td>-2</td>\n      <td>-2</td>\n      <td>-4</td>\n      <td>-14</td>\n      <td>-6</td>\n      <td>-6</td>\n      <td>-10</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>75</th>\n      <td>4</td>\n      <td>-66</td>\n      <td>-194</td>\n      <td>-154</td>\n      <td>-27</td>\n      <td>4</td>\n      <td>120</td>\n      <td>180</td>\n      <td>244</td>\n      <td>352</td>\n      <td>...</td>\n      <td>8</td>\n      <td>6</td>\n      <td>8</td>\n      <td>0</td>\n      <td>10</td>\n      <td>18</td>\n      <td>26</td>\n      <td>32</td>\n      <td>34</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>60</th>\n      <td>26</td>\n      <td>8</td>\n      <td>80</td>\n      <td>-14</td>\n      <td>-24</td>\n      <td>-92</td>\n      <td>-106</td>\n      <td>-120</td>\n      <td>-114</td>\n      <td>-104</td>\n      <td>...</td>\n      <td>40</td>\n      <td>86</td>\n      <td>58</td>\n      <td>50</td>\n      <td>76</td>\n      <td>98</td>\n      <td>100</td>\n      <td>102</td>\n      <td>94</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>151</th>\n      <td>58</td>\n      <td>86</td>\n      <td>148</td>\n      <td>275</td>\n      <td>338</td>\n      <td>278</td>\n      <td>150</td>\n      <td>22</td>\n      <td>-34</td>\n      <td>-12</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>103</th>\n      <td>-58</td>\n      <td>-186</td>\n      <td>-108</td>\n      <td>19</td>\n      <td>10</td>\n      <td>78</td>\n      <td>126</td>\n      <td>184</td>\n      <td>282</td>\n      <td>274</td>\n      <td>...</td>\n      <td>16</td>\n      <td>18</td>\n      <td>22</td>\n      <td>14</td>\n      <td>18</td>\n      <td>18</td>\n      <td>12</td>\n      <td>18</td>\n      <td>22</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>99</th>\n      <td>198</td>\n      <td>262</td>\n      <td>152</td>\n      <td>24</td>\n      <td>-86</td>\n      <td>-74</td>\n      <td>-68</td>\n      <td>-118</td>\n      <td>-64</td>\n      <td>-62</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>116</th>\n      <td>-6</td>\n      <td>-14</td>\n      <td>-98</td>\n      <td>-98</td>\n      <td>29</td>\n      <td>2</td>\n      <td>64</td>\n      <td>126</td>\n      <td>182</td>\n      <td>252</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>87</th>\n      <td>14</td>\n      <td>-90</td>\n      <td>-218</td>\n      <td>-96</td>\n      <td>31</td>\n      <td>48</td>\n      <td>146</td>\n      <td>208</td>\n      <td>278</td>\n      <td>368</td>\n      <td>...</td>\n      <td>10</td>\n      <td>8</td>\n      <td>4</td>\n      <td>4</td>\n      <td>18</td>\n      <td>22</td>\n      <td>28</td>\n      <td>36</td>\n      <td>26</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>200 rows Ã— 76 columns</p>\n</div>"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Max number of data points per heartbeat\n",
    "max_length = 75\n",
    "limit_of_samples = 100\n",
    "\n",
    "# Define paths\n",
    "normal_dir = './ecg/normal'\n",
    "abnormal_dir = './ecg/abnormal'\n",
    "# Labels\n",
    "normal = 0\n",
    "abnormal = 1\n",
    "\n",
    "\n",
    "def load_data_from_directory(directory, label, mode='constant', limit=-1):\n",
    "    data_list = []\n",
    "\n",
    "    for filename in os.listdir(directory):\n",
    "        if not filename.endswith('0') and not filename.endswith('1'):\n",
    "            continue\n",
    "        if limit == 0:\n",
    "            break\n",
    "        limit -= 1\n",
    "        path = os.path.join(directory, filename)\n",
    "        heartbeat = pd.read_csv(path, delimiter='\\s+', header=None)[1]\n",
    "\n",
    "        if len(heartbeat) < max_length:\n",
    "            if mode == 'constant':\n",
    "                heartbeat = np.pad(heartbeat, (0, max_length - len(heartbeat)), mode='constant',\n",
    "                                   constant_values=0)\n",
    "            elif mode == 'mean':\n",
    "                heartbeat = np.pad(heartbeat, (0, max_length - len(heartbeat)), mode='mean')\n",
    "        else:\n",
    "            heartbeat = heartbeat[:max_length]\n",
    "        heartbeat = {k: v for k, v in enumerate(heartbeat)}\n",
    "        heartbeat['label'] = label\n",
    "        data_list.append(heartbeat)\n",
    "\n",
    "    return data_list\n",
    "\n",
    "\n",
    "normal_data = load_data_from_directory(normal_dir, normal, limit=limit_of_samples)\n",
    "abnormal_data = load_data_from_directory(abnormal_dir, abnormal, limit=limit_of_samples)\n",
    "df = pd.DataFrame(normal_data + abnormal_data).sample(frac=1)\n",
    "df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-08T11:44:52.212864340Z",
     "start_time": "2023-11-08T11:44:51.641337279Z"
    }
   },
   "id": "e260f2ec046e5272"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Split into Train/Test Set"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e896196f1845c359"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "n = 0.3\n",
    "random_seed = 42\n",
    "np.random.seed(random_seed)\n",
    "\n",
    "X = df.iloc[:, :75]\n",
    "y = df['label']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=n, random_state=random_seed)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-08T11:44:52.213714005Z",
     "start_time": "2023-11-08T11:44:52.186126499Z"
    }
   },
   "id": "8e8d8f6476ce9973"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Resample via smote, because abnormal is underrepresented"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3019f2e0f4b09690"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "smote = SMOTE(sampling_strategy='minority')\n",
    "X_train, y_train = smote.fit_resample(X_train, y_train)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-08T11:44:52.249119509Z",
     "start_time": "2023-11-08T11:44:52.186644459Z"
    }
   },
   "id": "cde697034b6ced4"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Rescale features X"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "84658ac89c22b20a"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-08T11:44:52.433058554Z",
     "start_time": "2023-11-08T11:44:52.209836165Z"
    }
   },
   "id": "13481870bfaa984f"
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "15/15 [==============================] - 1s 2ms/step - loss: 0.6628 - accuracy: 0.6216 - precision_2: 0.9091 - recall_2: 0.2703    \n",
      "Epoch 2/150\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.5331 - accuracy: 0.7635 - precision_2: 0.8000 - recall_2: 0.7027\n",
      "Epoch 3/150\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4676 - accuracy: 0.8176 - precision_2: 0.7901 - recall_2: 0.8649\n",
      "Epoch 4/150\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4171 - accuracy: 0.8514 - precision_2: 0.8333 - recall_2: 0.8784\n",
      "Epoch 5/150\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.3833 - accuracy: 0.8649 - precision_2: 0.8462 - recall_2: 0.8919\n",
      "Epoch 6/150\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.3530 - accuracy: 0.8919 - precision_2: 0.8625 - recall_2: 0.9324\n",
      "Epoch 7/150\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.3223 - accuracy: 0.8851 - precision_2: 0.8701 - recall_2: 0.9054\n",
      "Epoch 8/150\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.2994 - accuracy: 0.9054 - precision_2: 0.8846 - recall_2: 0.9324\n",
      "Epoch 9/150\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.2769 - accuracy: 0.9122 - precision_2: 0.8961 - recall_2: 0.9324\n",
      "Epoch 10/150\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.2509 - accuracy: 0.9122 - precision_2: 0.8961 - recall_2: 0.9324\n",
      "Epoch 11/150\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.2329 - accuracy: 0.9324 - precision_2: 0.9324 - recall_2: 0.9324\n",
      "Epoch 12/150\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.2195 - accuracy: 0.9392 - precision_2: 0.9452 - recall_2: 0.9324\n",
      "Epoch 13/150\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.2044 - accuracy: 0.9392 - precision_2: 0.9333 - recall_2: 0.9459\n",
      "Epoch 14/150\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.1857 - accuracy: 0.9459 - precision_2: 0.9459 - recall_2: 0.9459\n",
      "Epoch 15/150\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.1742 - accuracy: 0.9459 - precision_2: 0.9459 - recall_2: 0.9459\n",
      "Epoch 16/150\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.1631 - accuracy: 0.9527 - precision_2: 0.9467 - recall_2: 0.9595\n",
      "Epoch 17/150\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.1505 - accuracy: 0.9527 - precision_2: 0.9589 - recall_2: 0.9459\n",
      "Epoch 18/150\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.1411 - accuracy: 0.9662 - precision_2: 0.9600 - recall_2: 0.9730\n",
      "Epoch 19/150\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.1328 - accuracy: 0.9730 - precision_2: 0.9605 - recall_2: 0.9865\n",
      "Epoch 20/150\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.1253 - accuracy: 0.9797 - precision_2: 1.0000 - recall_2: 0.9595\n",
      "Epoch 21/150\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.1136 - accuracy: 0.9865 - precision_2: 0.9865 - recall_2: 0.9865\n",
      "Epoch 22/150\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.1076 - accuracy: 0.9932 - precision_2: 1.0000 - recall_2: 0.9865\n",
      "Epoch 23/150\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.1029 - accuracy: 0.9932 - precision_2: 1.0000 - recall_2: 0.9865\n",
      "Epoch 24/150\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0923 - accuracy: 0.9932 - precision_2: 1.0000 - recall_2: 0.9865\n",
      "Epoch 25/150\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0870 - accuracy: 0.9932 - precision_2: 1.0000 - recall_2: 0.9865\n",
      "Epoch 26/150\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0813 - accuracy: 0.9932 - precision_2: 1.0000 - recall_2: 0.9865\n",
      "Epoch 27/150\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0779 - accuracy: 0.9932 - precision_2: 1.0000 - recall_2: 0.9865\n",
      "Epoch 28/150\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0755 - accuracy: 0.9932 - precision_2: 1.0000 - recall_2: 0.9865\n",
      "Epoch 29/150\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0670 - accuracy: 0.9932 - precision_2: 1.0000 - recall_2: 0.9865\n",
      "Epoch 30/150\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0625 - accuracy: 0.9932 - precision_2: 1.0000 - recall_2: 0.9865\n",
      "Epoch 31/150\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0589 - accuracy: 0.9932 - precision_2: 1.0000 - recall_2: 0.9865\n",
      "Epoch 32/150\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0568 - accuracy: 0.9932 - precision_2: 1.0000 - recall_2: 0.9865\n",
      "Epoch 33/150\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0538 - accuracy: 0.9932 - precision_2: 1.0000 - recall_2: 0.9865\n",
      "Epoch 34/150\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0526 - accuracy: 0.9932 - precision_2: 1.0000 - recall_2: 0.9865\n",
      "Epoch 35/150\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0560 - accuracy: 0.9932 - precision_2: 1.0000 - recall_2: 0.9865\n",
      "Epoch 36/150\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0436 - accuracy: 0.9932 - precision_2: 1.0000 - recall_2: 0.9865\n",
      "Epoch 37/150\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0431 - accuracy: 0.9932 - precision_2: 1.0000 - recall_2: 0.9865\n",
      "Epoch 38/150\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0410 - accuracy: 0.9932 - precision_2: 1.0000 - recall_2: 0.9865\n",
      "Epoch 39/150\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0384 - accuracy: 0.9932 - precision_2: 1.0000 - recall_2: 0.9865\n",
      "Epoch 40/150\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0337 - accuracy: 0.9932 - precision_2: 1.0000 - recall_2: 0.9865\n",
      "Epoch 41/150\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0326 - accuracy: 0.9932 - precision_2: 1.0000 - recall_2: 0.9865\n",
      "Epoch 42/150\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0304 - accuracy: 0.9932 - precision_2: 1.0000 - recall_2: 0.9865\n",
      "Epoch 43/150\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0278 - accuracy: 0.9932 - precision_2: 1.0000 - recall_2: 0.9865\n",
      "Epoch 44/150\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0270 - accuracy: 0.9932 - precision_2: 1.0000 - recall_2: 0.9865\n",
      "Epoch 45/150\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0260 - accuracy: 0.9932 - precision_2: 1.0000 - recall_2: 0.9865\n",
      "Epoch 46/150\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0236 - accuracy: 0.9932 - precision_2: 1.0000 - recall_2: 0.9865\n",
      "Epoch 47/150\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0223 - accuracy: 0.9932 - precision_2: 1.0000 - recall_2: 0.9865\n",
      "Epoch 48/150\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0222 - accuracy: 0.9932 - precision_2: 1.0000 - recall_2: 0.9865\n",
      "Epoch 49/150\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0202 - accuracy: 0.9932 - precision_2: 1.0000 - recall_2: 0.9865\n",
      "Epoch 50/150\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0203 - accuracy: 0.9932 - precision_2: 1.0000 - recall_2: 0.9865\n",
      "Epoch 51/150\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0161 - accuracy: 0.9932 - precision_2: 1.0000 - recall_2: 0.9865\n",
      "Epoch 52/150\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.0157 - accuracy: 0.9932 - precision_2: 1.0000 - recall_2: 0.9865\n",
      "Epoch 53/150\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0141 - accuracy: 1.0000 - precision_2: 1.0000 - recall_2: 1.0000\n",
      "Epoch 54/150\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0147 - accuracy: 1.0000 - precision_2: 1.0000 - recall_2: 1.0000\n",
      "Epoch 55/150\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0130 - accuracy: 1.0000 - precision_2: 1.0000 - recall_2: 1.0000\n",
      "Epoch 56/150\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0120 - accuracy: 1.0000 - precision_2: 1.0000 - recall_2: 1.0000\n",
      "Epoch 57/150\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0106 - accuracy: 1.0000 - precision_2: 1.0000 - recall_2: 1.0000\n",
      "Epoch 58/150\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0110 - accuracy: 1.0000 - precision_2: 1.0000 - recall_2: 1.0000\n",
      "Epoch 59/150\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0103 - accuracy: 1.0000 - precision_2: 1.0000 - recall_2: 1.0000\n",
      "Epoch 60/150\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0094 - accuracy: 1.0000 - precision_2: 1.0000 - recall_2: 1.0000\n",
      "Epoch 61/150\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0089 - accuracy: 1.0000 - precision_2: 1.0000 - recall_2: 1.0000\n",
      "Epoch 62/150\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0094 - accuracy: 1.0000 - precision_2: 1.0000 - recall_2: 1.0000\n",
      "Epoch 63/150\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0097 - accuracy: 1.0000 - precision_2: 1.0000 - recall_2: 1.0000\n",
      "Epoch 64/150\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0077 - accuracy: 1.0000 - precision_2: 1.0000 - recall_2: 1.0000\n",
      "Epoch 65/150\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0068 - accuracy: 1.0000 - precision_2: 1.0000 - recall_2: 1.0000\n",
      "Epoch 66/150\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0068 - accuracy: 1.0000 - precision_2: 1.0000 - recall_2: 1.0000\n",
      "Epoch 67/150\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0063 - accuracy: 1.0000 - precision_2: 1.0000 - recall_2: 1.0000\n",
      "Epoch 68/150\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0061 - accuracy: 1.0000 - precision_2: 1.0000 - recall_2: 1.0000\n",
      "Epoch 69/150\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0058 - accuracy: 1.0000 - precision_2: 1.0000 - recall_2: 1.0000\n",
      "Epoch 70/150\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0053 - accuracy: 1.0000 - precision_2: 1.0000 - recall_2: 1.0000\n",
      "Epoch 71/150\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0051 - accuracy: 1.0000 - precision_2: 1.0000 - recall_2: 1.0000\n",
      "Epoch 72/150\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0046 - accuracy: 1.0000 - precision_2: 1.0000 - recall_2: 1.0000\n",
      "Epoch 73/150\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0044 - accuracy: 1.0000 - precision_2: 1.0000 - recall_2: 1.0000\n",
      "Epoch 74/150\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0043 - accuracy: 1.0000 - precision_2: 1.0000 - recall_2: 1.0000\n",
      "Epoch 75/150\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0041 - accuracy: 1.0000 - precision_2: 1.0000 - recall_2: 1.0000\n",
      "Epoch 76/150\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0040 - accuracy: 1.0000 - precision_2: 1.0000 - recall_2: 1.0000\n",
      "Epoch 77/150\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0041 - accuracy: 1.0000 - precision_2: 1.0000 - recall_2: 1.0000\n",
      "Epoch 78/150\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0037 - accuracy: 1.0000 - precision_2: 1.0000 - recall_2: 1.0000\n",
      "Epoch 79/150\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0034 - accuracy: 1.0000 - precision_2: 1.0000 - recall_2: 1.0000\n",
      "Epoch 80/150\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0034 - accuracy: 1.0000 - precision_2: 1.0000 - recall_2: 1.0000\n",
      "Epoch 81/150\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0032 - accuracy: 1.0000 - precision_2: 1.0000 - recall_2: 1.0000\n",
      "Epoch 82/150\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0031 - accuracy: 1.0000 - precision_2: 1.0000 - recall_2: 1.0000\n",
      "Epoch 83/150\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0029 - accuracy: 1.0000 - precision_2: 1.0000 - recall_2: 1.0000\n",
      "Epoch 84/150\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0028 - accuracy: 1.0000 - precision_2: 1.0000 - recall_2: 1.0000\n",
      "Epoch 85/150\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0028 - accuracy: 1.0000 - precision_2: 1.0000 - recall_2: 1.0000\n",
      "Epoch 86/150\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0026 - accuracy: 1.0000 - precision_2: 1.0000 - recall_2: 1.0000\n",
      "Epoch 87/150\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0025 - accuracy: 1.0000 - precision_2: 1.0000 - recall_2: 1.0000\n",
      "Epoch 88/150\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0025 - accuracy: 1.0000 - precision_2: 1.0000 - recall_2: 1.0000\n",
      "Epoch 89/150\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0025 - accuracy: 1.0000 - precision_2: 1.0000 - recall_2: 1.0000\n",
      "Epoch 90/150\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0023 - accuracy: 1.0000 - precision_2: 1.0000 - recall_2: 1.0000\n",
      "Epoch 91/150\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0022 - accuracy: 1.0000 - precision_2: 1.0000 - recall_2: 1.0000\n",
      "Epoch 92/150\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0022 - accuracy: 1.0000 - precision_2: 1.0000 - recall_2: 1.0000\n",
      "Epoch 93/150\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0020 - accuracy: 1.0000 - precision_2: 1.0000 - recall_2: 1.0000\n",
      "Epoch 94/150\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0020 - accuracy: 1.0000 - precision_2: 1.0000 - recall_2: 1.0000\n",
      "Epoch 95/150\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0020 - accuracy: 1.0000 - precision_2: 1.0000 - recall_2: 1.0000\n",
      "Epoch 96/150\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0020 - accuracy: 1.0000 - precision_2: 1.0000 - recall_2: 1.0000\n",
      "Epoch 97/150\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0018 - accuracy: 1.0000 - precision_2: 1.0000 - recall_2: 1.0000\n",
      "Epoch 98/150\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0017 - accuracy: 1.0000 - precision_2: 1.0000 - recall_2: 1.0000\n",
      "Epoch 99/150\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0017 - accuracy: 1.0000 - precision_2: 1.0000 - recall_2: 1.0000\n",
      "Epoch 100/150\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0016 - accuracy: 1.0000 - precision_2: 1.0000 - recall_2: 1.0000\n",
      "Epoch 101/150\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0016 - accuracy: 1.0000 - precision_2: 1.0000 - recall_2: 1.0000\n",
      "Epoch 102/150\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0016 - accuracy: 1.0000 - precision_2: 1.0000 - recall_2: 1.0000\n",
      "Epoch 103/150\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0017 - accuracy: 1.0000 - precision_2: 1.0000 - recall_2: 1.0000\n",
      "Epoch 104/150\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0016 - accuracy: 1.0000 - precision_2: 1.0000 - recall_2: 1.0000\n",
      "Epoch 105/150\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0015 - accuracy: 1.0000 - precision_2: 1.0000 - recall_2: 1.0000\n",
      "Epoch 106/150\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0015 - accuracy: 1.0000 - precision_2: 1.0000 - recall_2: 1.0000\n",
      "Epoch 107/150\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0014 - accuracy: 1.0000 - precision_2: 1.0000 - recall_2: 1.0000\n",
      "Epoch 108/150\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0013 - accuracy: 1.0000 - precision_2: 1.0000 - recall_2: 1.0000\n",
      "Epoch 109/150\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0013 - accuracy: 1.0000 - precision_2: 1.0000 - recall_2: 1.0000\n",
      "Epoch 110/150\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0013 - accuracy: 1.0000 - precision_2: 1.0000 - recall_2: 1.0000\n",
      "Epoch 111/150\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0013 - accuracy: 1.0000 - precision_2: 1.0000 - recall_2: 1.0000\n",
      "Epoch 112/150\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0012 - accuracy: 1.0000 - precision_2: 1.0000 - recall_2: 1.0000\n",
      "Epoch 113/150\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0012 - accuracy: 1.0000 - precision_2: 1.0000 - recall_2: 1.0000\n",
      "Epoch 114/150\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0011 - accuracy: 1.0000 - precision_2: 1.0000 - recall_2: 1.0000\n",
      "Epoch 115/150\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0011 - accuracy: 1.0000 - precision_2: 1.0000 - recall_2: 1.0000\n",
      "Epoch 116/150\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0011 - accuracy: 1.0000 - precision_2: 1.0000 - recall_2: 1.0000\n",
      "Epoch 117/150\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0010 - accuracy: 1.0000 - precision_2: 1.0000 - recall_2: 1.0000\n",
      "Epoch 118/150\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0010 - accuracy: 1.0000 - precision_2: 1.0000 - recall_2: 1.0000\n",
      "Epoch 119/150\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 9.8691e-04 - accuracy: 1.0000 - precision_2: 1.0000 - recall_2: 1.0000\n",
      "Epoch 120/150\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 9.7252e-04 - accuracy: 1.0000 - precision_2: 1.0000 - recall_2: 1.0000\n",
      "Epoch 121/150\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 9.4899e-04 - accuracy: 1.0000 - precision_2: 1.0000 - recall_2: 1.0000\n",
      "Epoch 122/150\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 9.2588e-04 - accuracy: 1.0000 - precision_2: 1.0000 - recall_2: 1.0000\n",
      "Epoch 123/150\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 9.0245e-04 - accuracy: 1.0000 - precision_2: 1.0000 - recall_2: 1.0000\n",
      "Epoch 124/150\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 8.8436e-04 - accuracy: 1.0000 - precision_2: 1.0000 - recall_2: 1.0000\n",
      "Epoch 125/150\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 8.6473e-04 - accuracy: 1.0000 - precision_2: 1.0000 - recall_2: 1.0000\n",
      "Epoch 126/150\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 8.6049e-04 - accuracy: 1.0000 - precision_2: 1.0000 - recall_2: 1.0000\n",
      "Epoch 127/150\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 8.2188e-04 - accuracy: 1.0000 - precision_2: 1.0000 - recall_2: 1.0000\n",
      "Epoch 128/150\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 8.1409e-04 - accuracy: 1.0000 - precision_2: 1.0000 - recall_2: 1.0000\n",
      "Epoch 129/150\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 7.9016e-04 - accuracy: 1.0000 - precision_2: 1.0000 - recall_2: 1.0000\n",
      "Epoch 130/150\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 7.8386e-04 - accuracy: 1.0000 - precision_2: 1.0000 - recall_2: 1.0000\n",
      "Epoch 131/150\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 7.4417e-04 - accuracy: 1.0000 - precision_2: 1.0000 - recall_2: 1.0000\n",
      "Epoch 132/150\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 7.5257e-04 - accuracy: 1.0000 - precision_2: 1.0000 - recall_2: 1.0000\n",
      "Epoch 133/150\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 7.1733e-04 - accuracy: 1.0000 - precision_2: 1.0000 - recall_2: 1.0000\n",
      "Epoch 134/150\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 7.1780e-04 - accuracy: 1.0000 - precision_2: 1.0000 - recall_2: 1.0000\n",
      "Epoch 135/150\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 6.9203e-04 - accuracy: 1.0000 - precision_2: 1.0000 - recall_2: 1.0000\n",
      "Epoch 136/150\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 6.8236e-04 - accuracy: 1.0000 - precision_2: 1.0000 - recall_2: 1.0000\n",
      "Epoch 137/150\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 6.6404e-04 - accuracy: 1.0000 - precision_2: 1.0000 - recall_2: 1.0000\n",
      "Epoch 138/150\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 6.6533e-04 - accuracy: 1.0000 - precision_2: 1.0000 - recall_2: 1.0000\n",
      "Epoch 139/150\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 6.4876e-04 - accuracy: 1.0000 - precision_2: 1.0000 - recall_2: 1.0000\n",
      "Epoch 140/150\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 6.3425e-04 - accuracy: 1.0000 - precision_2: 1.0000 - recall_2: 1.0000\n",
      "Epoch 141/150\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 6.1062e-04 - accuracy: 1.0000 - precision_2: 1.0000 - recall_2: 1.0000\n",
      "Epoch 142/150\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 6.0000e-04 - accuracy: 1.0000 - precision_2: 1.0000 - recall_2: 1.0000\n",
      "Epoch 143/150\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 5.8641e-04 - accuracy: 1.0000 - precision_2: 1.0000 - recall_2: 1.0000\n",
      "Epoch 144/150\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 5.8640e-04 - accuracy: 1.0000 - precision_2: 1.0000 - recall_2: 1.0000\n",
      "Epoch 145/150\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 5.8958e-04 - accuracy: 1.0000 - precision_2: 1.0000 - recall_2: 1.0000\n",
      "Epoch 146/150\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 5.5629e-04 - accuracy: 1.0000 - precision_2: 1.0000 - recall_2: 1.0000\n",
      "Epoch 147/150\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 5.5341e-04 - accuracy: 1.0000 - precision_2: 1.0000 - recall_2: 1.0000\n",
      "Epoch 148/150\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 5.3357e-04 - accuracy: 1.0000 - precision_2: 1.0000 - recall_2: 1.0000\n",
      "Epoch 149/150\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 5.2614e-04 - accuracy: 1.0000 - precision_2: 1.0000 - recall_2: 1.0000\n",
      "Epoch 150/150\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 5.0951e-04 - accuracy: 1.0000 - precision_2: 1.0000 - recall_2: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 4ms/step - loss: 1.4479 - accuracy: 0.8000 - precision_2: 0.7750 - recall_2: 0.9118\n",
      "Accuracy on testing data: 80.00\n",
      "Precision on testing data: 77.50\n",
      "Recall on testing data: 91.18\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import matplotlib.pyplot as plt\n",
    "from keras import metrics\n",
    "\n",
    "# Initialize the constructor\n",
    "model = Sequential()\n",
    "\n",
    "# Add an input layer \n",
    "model.add(Dense(64, activation='relu', input_shape=(75,)))\n",
    "\n",
    "# Add one hidden layer \n",
    "model.add(Dense(32, activation='relu'))\n",
    "\n",
    "# Add an output layer \n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy', metrics.Precision(), metrics.Recall()])\n",
    "history = model.fit(X_train, y_train, epochs=150, batch_size=10, verbose=1)\n",
    "\n",
    "plt.plot(history.history['accuracy'], label='accuracy')\n",
    "plt.plot(history.history['loss'], label='training loss')\n",
    "plt.legend()\n",
    "plt.gray()\n",
    "plt.show()\n",
    "\n",
    "_, accuracy, precision, recall = model.evaluate(X_test, y_test)\n",
    "print('Accuracy on testing data: %.2f' % (accuracy * 100))\n",
    "print('Precision on testing data: %.2f' % (precision * 100))\n",
    "print('Recall on testing data: %.2f' % (recall * 100))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-08T12:04:38.034561065Z",
     "start_time": "2023-11-08T12:04:33.485652477Z"
    }
   },
   "id": "893ca021f2b77ec2"
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [],
   "source": [
    "from keras_tuner import HyperParameters\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "import keras\n",
    "\n",
    "\n",
    "def build_model(hp: HyperParameters):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units=hp.Int('units_0',\n",
    "                                 min_value=32,\n",
    "                                 max_value=512,\n",
    "                                 step=32),\n",
    "                    activation='relu',\n",
    "                    input_dim=75))\n",
    "    for i in range(hp.Int('num_layers', 1, 7)):\n",
    "        model.add(Dense(units=hp.Int('units_' + str(i + 1),\n",
    "                                     min_value=32,\n",
    "                                     max_value=1024,\n",
    "                                     step=32),\n",
    "                        activation='relu'))\n",
    "        model.add(Dropout(hp.Float('dropout_' + str(i + 1),\n",
    "                                   min_value=0.0,\n",
    "                                   max_value=0.5,\n",
    "                                   step=0.1)))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(\n",
    "            hp.Choice('learning_rate',\n",
    "                      values=[1e-2, 1e-3, 1e-4])),\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy', metrics.Precision(), metrics.Recall()])\n",
    "    return model"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-08T12:26:59.918175985Z",
     "start_time": "2023-11-08T12:26:59.910463978Z"
    }
   },
   "id": "19a6ce2b4ee14cb0"
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 5 Complete [00h 00m 32s]\n",
      "val_accuracy: 0.9111111164093018\n",
      "\n",
      "Best val_accuracy So Far: 0.9222222367922465\n",
      "Total elapsed time: 00h 03m 09s\n"
     ]
    }
   ],
   "source": [
    "from keras_tuner.tuners import RandomSearch\n",
    "\n",
    "tuner = RandomSearch(\n",
    "    build_model,\n",
    "    objective='val_accuracy',\n",
    "    max_trials=5,\n",
    "    executions_per_trial=3,\n",
    "    directory='.model_cache',\n",
    "    project_name='Lab 03: ECG'\n",
    ")\n",
    "\n",
    "tuner.search(X_train, y_train,\n",
    "             epochs=150,\n",
    "             batch_size=10,\n",
    "             validation_data=(X_test, y_test))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4cdc1323ff11793c"
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2866 - accuracy: 0.9333 - precision: 0.9412 - recall: 0.9412\n",
      "Test loss: 0.2865874469280243\n",
      "Test accuracy: 0.9333333373069763\n",
      "Test precision: 0.9411764740943909\n",
      "Test recall: 0.9411764740943909\n"
     ]
    }
   ],
   "source": [
    "models = tuner.get_best_models(num_models=1)\n",
    "\n",
    "# Evaluate the best model\n",
    "for model in models:\n",
    "    loss, accuracy, precision, recall = model.evaluate(X_test, y_test)\n",
    "    print('Test loss:', loss)\n",
    "    print('Test accuracy:', accuracy)\n",
    "    print('Test precision:', precision)\n",
    "    print('Test recall:', recall)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-08T12:32:35.094761879Z",
     "start_time": "2023-11-08T12:32:34.185070546Z"
    }
   },
   "id": "2fa02d801b7f1724"
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The hyperparameter search is complete. The optimal number of units in the first layer is 352, \n",
      "the optimal number of layers is 3, and the optimal learning rate is 0.01.\n"
     ]
    },
    {
     "data": {
      "text/plain": "{'_name_scopes': [],\n '_conditions': [],\n '_hps': defaultdict(list,\n             {'units_0': [Int(name: 'units_0', min_value: 32, max_value: 512, step: 32, sampling: linear, default: 32)],\n              'num_layers': [Int(name: 'num_layers', min_value: 1, max_value: 7, step: 1, sampling: linear, default: 1)],\n              'units_1': [Int(name: 'units_1', min_value: 32, max_value: 1024, step: 32, sampling: linear, default: 32)],\n              'dropout_1': [Float(name: 'dropout_1', min_value: '0.0', max_value: '0.5', step: '0.1', sampling: 'linear', default: '0.0')],\n              'learning_rate': [Choice(name: 'learning_rate', values: [0.01, 0.001, 0.0001], ordered: True, default: 0.01)],\n              'units_2': [Int(name: 'units_2', min_value: 32, max_value: 1024, step: 32, sampling: linear, default: 32)],\n              'dropout_2': [Float(name: 'dropout_2', min_value: '0.0', max_value: '0.5', step: '0.1', sampling: 'linear', default: '0.0')],\n              'units_3': [Int(name: 'units_3', min_value: 32, max_value: 1024, step: 32, sampling: linear, default: 32)],\n              'dropout_3': [Float(name: 'dropout_3', min_value: '0.0', max_value: '0.5', step: '0.1', sampling: 'linear', default: '0.0')]}),\n '_space': [Int(name: 'units_0', min_value: 32, max_value: 512, step: 32, sampling: linear, default: 32),\n  Int(name: 'num_layers', min_value: 1, max_value: 7, step: 1, sampling: linear, default: 1),\n  Int(name: 'units_1', min_value: 32, max_value: 1024, step: 32, sampling: linear, default: 32),\n  Float(name: 'dropout_1', min_value: '0.0', max_value: '0.5', step: '0.1', sampling: 'linear', default: '0.0'),\n  Choice(name: 'learning_rate', values: [0.01, 0.001, 0.0001], ordered: True, default: 0.01),\n  Int(name: 'units_2', min_value: 32, max_value: 1024, step: 32, sampling: linear, default: 32),\n  Float(name: 'dropout_2', min_value: '0.0', max_value: '0.5', step: '0.1', sampling: 'linear', default: '0.0'),\n  Int(name: 'units_3', min_value: 32, max_value: 1024, step: 32, sampling: linear, default: 32),\n  Float(name: 'dropout_3', min_value: '0.0', max_value: '0.5', step: '0.1', sampling: 'linear', default: '0.0')],\n 'values': {'units_0': 352,\n  'num_layers': 3,\n  'units_1': 640,\n  'dropout_1': 0.0,\n  'learning_rate': 0.01,\n  'units_2': 32,\n  'dropout_2': 0.0,\n  'units_3': 32,\n  'dropout_3': 0.0},\n 'active_scopes': [],\n 'inactive_scopes': []}"
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_hyperparameters = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "print(f\"\"\"\n",
    "The hyperparameter search is complete. The optimal number of units in the first layer is {best_hyperparameters.get('units_0')}, \n",
    "the optimal number of layers is {best_hyperparameters.get('num_layers')}, and the optimal learning rate is {best_hyperparameters.get('learning_rate')}.\n",
    "\"\"\")\n",
    "best_hyperparameters.__dict__"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-08T12:34:14.952170794Z",
     "start_time": "2023-11-08T12:34:14.945606126Z"
    }
   },
   "id": "8d6698349bb0d9ab"
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-08T11:49:26.698470513Z",
     "start_time": "2023-11-08T11:49:26.697816690Z"
    }
   },
   "id": "d5aaf0e49dbcb216"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
