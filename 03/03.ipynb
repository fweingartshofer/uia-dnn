{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# ECG\n",
    "Load data\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e6142749e34afa43"
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [
    {
     "data": {
      "text/plain": "       0    1    2    3    4    5    6    7    8    9  ...  66   67   68  69  \\\n30   -52 -180  -68   59   72  162  210  286  356  350  ...  10   18    8  14   \n173  162  220  298  264  136   12   -2  -20  -16  -24  ... -46 -148 -178 -51   \n140  128  255  324  266  138   10   98  140  126  148  ...   6   -8   -2  -2   \n75     4  -66 -194 -154  -27    4  120  180  244  352  ...   8    6    8   0   \n60    26    8   80  -14  -24  -92 -106 -120 -114 -104  ...  40   86   58  50   \n..   ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ..  ...  ...  ..   \n151   58   86  148  275  338  278  150   22  -34  -12  ...   0    0    0   0   \n103  -58 -186 -108   19   10   78  126  184  282  274  ...  16   18   22  14   \n99   198  262  152   24  -86  -74  -68 -118  -64  -62  ...   0    0    0   0   \n116   -6  -14  -98  -98   29    2   64  126  182  252  ...   0    0    0   0   \n87    14  -90 -218  -96   31   48  146  208  278  368  ...  10    8    4   4   \n\n     70  71   72   73  74  label  \n30   10  10   12   10  12      0  \n173  -8  36    0    0   0      1  \n140  -4 -14   -6   -6 -10      1  \n75   10  18   26   32  34      0  \n60   76  98  100  102  94      0  \n..   ..  ..  ...  ...  ..    ...  \n151   0   0    0    0   0      1  \n103  18  18   12   18  22      1  \n99    0   0    0    0   0      0  \n116   0   0    0    0   0      1  \n87   18  22   28   36  26      0  \n\n[200 rows x 76 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>...</th>\n      <th>66</th>\n      <th>67</th>\n      <th>68</th>\n      <th>69</th>\n      <th>70</th>\n      <th>71</th>\n      <th>72</th>\n      <th>73</th>\n      <th>74</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>30</th>\n      <td>-52</td>\n      <td>-180</td>\n      <td>-68</td>\n      <td>59</td>\n      <td>72</td>\n      <td>162</td>\n      <td>210</td>\n      <td>286</td>\n      <td>356</td>\n      <td>350</td>\n      <td>...</td>\n      <td>10</td>\n      <td>18</td>\n      <td>8</td>\n      <td>14</td>\n      <td>10</td>\n      <td>10</td>\n      <td>12</td>\n      <td>10</td>\n      <td>12</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>173</th>\n      <td>162</td>\n      <td>220</td>\n      <td>298</td>\n      <td>264</td>\n      <td>136</td>\n      <td>12</td>\n      <td>-2</td>\n      <td>-20</td>\n      <td>-16</td>\n      <td>-24</td>\n      <td>...</td>\n      <td>-46</td>\n      <td>-148</td>\n      <td>-178</td>\n      <td>-51</td>\n      <td>-8</td>\n      <td>36</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>140</th>\n      <td>128</td>\n      <td>255</td>\n      <td>324</td>\n      <td>266</td>\n      <td>138</td>\n      <td>10</td>\n      <td>98</td>\n      <td>140</td>\n      <td>126</td>\n      <td>148</td>\n      <td>...</td>\n      <td>6</td>\n      <td>-8</td>\n      <td>-2</td>\n      <td>-2</td>\n      <td>-4</td>\n      <td>-14</td>\n      <td>-6</td>\n      <td>-6</td>\n      <td>-10</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>75</th>\n      <td>4</td>\n      <td>-66</td>\n      <td>-194</td>\n      <td>-154</td>\n      <td>-27</td>\n      <td>4</td>\n      <td>120</td>\n      <td>180</td>\n      <td>244</td>\n      <td>352</td>\n      <td>...</td>\n      <td>8</td>\n      <td>6</td>\n      <td>8</td>\n      <td>0</td>\n      <td>10</td>\n      <td>18</td>\n      <td>26</td>\n      <td>32</td>\n      <td>34</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>60</th>\n      <td>26</td>\n      <td>8</td>\n      <td>80</td>\n      <td>-14</td>\n      <td>-24</td>\n      <td>-92</td>\n      <td>-106</td>\n      <td>-120</td>\n      <td>-114</td>\n      <td>-104</td>\n      <td>...</td>\n      <td>40</td>\n      <td>86</td>\n      <td>58</td>\n      <td>50</td>\n      <td>76</td>\n      <td>98</td>\n      <td>100</td>\n      <td>102</td>\n      <td>94</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>151</th>\n      <td>58</td>\n      <td>86</td>\n      <td>148</td>\n      <td>275</td>\n      <td>338</td>\n      <td>278</td>\n      <td>150</td>\n      <td>22</td>\n      <td>-34</td>\n      <td>-12</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>103</th>\n      <td>-58</td>\n      <td>-186</td>\n      <td>-108</td>\n      <td>19</td>\n      <td>10</td>\n      <td>78</td>\n      <td>126</td>\n      <td>184</td>\n      <td>282</td>\n      <td>274</td>\n      <td>...</td>\n      <td>16</td>\n      <td>18</td>\n      <td>22</td>\n      <td>14</td>\n      <td>18</td>\n      <td>18</td>\n      <td>12</td>\n      <td>18</td>\n      <td>22</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>99</th>\n      <td>198</td>\n      <td>262</td>\n      <td>152</td>\n      <td>24</td>\n      <td>-86</td>\n      <td>-74</td>\n      <td>-68</td>\n      <td>-118</td>\n      <td>-64</td>\n      <td>-62</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>116</th>\n      <td>-6</td>\n      <td>-14</td>\n      <td>-98</td>\n      <td>-98</td>\n      <td>29</td>\n      <td>2</td>\n      <td>64</td>\n      <td>126</td>\n      <td>182</td>\n      <td>252</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>87</th>\n      <td>14</td>\n      <td>-90</td>\n      <td>-218</td>\n      <td>-96</td>\n      <td>31</td>\n      <td>48</td>\n      <td>146</td>\n      <td>208</td>\n      <td>278</td>\n      <td>368</td>\n      <td>...</td>\n      <td>10</td>\n      <td>8</td>\n      <td>4</td>\n      <td>4</td>\n      <td>18</td>\n      <td>22</td>\n      <td>28</td>\n      <td>36</td>\n      <td>26</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>200 rows Ã— 76 columns</p>\n</div>"
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Max number of data points per heartbeat\n",
    "max_length = 75\n",
    "limit_of_samples = 100\n",
    "\n",
    "# Define paths\n",
    "normal_dir = './ecg/normal'\n",
    "abnormal_dir = './ecg/abnormal'\n",
    "# Labels\n",
    "normal = 0\n",
    "abnormal = 1\n",
    "\n",
    "\n",
    "def load_data_from_directory(directory, label, mode='constant', limit=-1):\n",
    "    data_list = []\n",
    "\n",
    "    for filename in os.listdir(directory):\n",
    "        if not filename.endswith('0') and not filename.endswith('1'):\n",
    "            continue\n",
    "        if limit == 0:\n",
    "            break\n",
    "        limit -= 1\n",
    "        path = os.path.join(directory, filename)\n",
    "        heartbeat = pd.read_csv(path, delimiter='\\s+', header=None)[1]\n",
    "\n",
    "        if len(heartbeat) < max_length:\n",
    "            if mode == 'constant':\n",
    "                heartbeat = np.pad(heartbeat, (0, max_length - len(heartbeat)), mode='constant',\n",
    "                                   constant_values=0)\n",
    "            elif mode == 'mean':\n",
    "                heartbeat = np.pad(heartbeat, (0, max_length - len(heartbeat)), mode='mean')\n",
    "        else:\n",
    "            heartbeat = heartbeat[:max_length]\n",
    "        heartbeat = {k: v for k, v in enumerate(heartbeat)}\n",
    "        heartbeat['label'] = label\n",
    "        data_list.append(heartbeat)\n",
    "\n",
    "    return data_list\n",
    "\n",
    "\n",
    "normal_data = load_data_from_directory(normal_dir, normal, limit=limit_of_samples)\n",
    "abnormal_data = load_data_from_directory(abnormal_dir, abnormal, limit=limit_of_samples)\n",
    "df = pd.DataFrame(normal_data + abnormal_data).sample(frac=1)\n",
    "df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-06T16:14:48.653954989Z",
     "start_time": "2023-11-06T16:14:47.079779190Z"
    }
   },
   "id": "e260f2ec046e5272"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Split into Train/Test Set"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e896196f1845c359"
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "n = 0.3\n",
    "random_seed = 42\n",
    "np.random.seed(random_seed)\n",
    "\n",
    "X = df.iloc[:, :75]\n",
    "y = df['label']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=n, random_state=random_seed)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-06T16:14:48.685281396Z",
     "start_time": "2023-11-06T16:14:48.621197274Z"
    }
   },
   "id": "8e8d8f6476ce9973"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Resample via smote, because abnormal is underrepresented"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3019f2e0f4b09690"
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "smote = SMOTE(sampling_strategy='minority')\n",
    "X_train, y_train = smote.fit_resample(X_train, y_train)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-06T16:14:48.769291875Z",
     "start_time": "2023-11-06T16:14:48.625487909Z"
    }
   },
   "id": "cde697034b6ced4"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Rescale features X"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "84658ac89c22b20a"
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[-1.40460573, -1.13433046, -0.30192821, ..., -0.41745437,\n        -0.45642824, -0.52284044],\n       [-0.52277266, -1.01666151, -1.49226582, ...,  0.23691365,\n         1.00056231,  1.09346002],\n       [ 0.54802464,  0.72222411,  0.94867967, ...,  2.30907903,\n         3.18604814,  3.24852731],\n       ...,\n       [-0.33380843, -0.45446541, -1.06032897, ...,  0.34597498,\n         0.40452072,  0.82407661],\n       [ 0.48503656,  0.42151457,  0.15512126, ..., -0.85369971,\n        -0.72133562, -0.11876532],\n       [ 0.21208823,  0.63070381,  0.95872471, ...,  1.327527  ,\n         2.0601918 ,  2.91179804]])"
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "X_test"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-06T16:14:49.021799191Z",
     "start_time": "2023-11-06T16:14:48.702198280Z"
    }
   },
   "id": "13481870bfaa984f"
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "15/15 [==============================] - 3s 8ms/step - loss: 0.6253 - accuracy: 0.6892\n",
      "Epoch 2/150\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.5047 - accuracy: 0.7703\n",
      "Epoch 3/150\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 0.4468 - accuracy: 0.8108\n",
      "Epoch 4/150\n",
      "15/15 [==============================] - 0s 17ms/step - loss: 0.3990 - accuracy: 0.8311\n",
      "Epoch 5/150\n",
      "15/15 [==============================] - 0s 16ms/step - loss: 0.3654 - accuracy: 0.8581\n",
      "Epoch 6/150\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.3331 - accuracy: 0.8716\n",
      "Epoch 7/150\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.3034 - accuracy: 0.8919\n",
      "Epoch 8/150\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.2852 - accuracy: 0.8919\n",
      "Epoch 9/150\n",
      "15/15 [==============================] - 0s 16ms/step - loss: 0.2623 - accuracy: 0.8986\n",
      "Epoch 10/150\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.2568 - accuracy: 0.8986\n",
      "Epoch 11/150\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.2266 - accuracy: 0.9189\n",
      "Epoch 12/150\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 0.2123 - accuracy: 0.9392\n",
      "Epoch 13/150\n",
      "15/15 [==============================] - 0s 16ms/step - loss: 0.2006 - accuracy: 0.9257\n",
      "Epoch 14/150\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 0.1899 - accuracy: 0.9392\n",
      "Epoch 15/150\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.1726 - accuracy: 0.9527\n",
      "Epoch 16/150\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 0.1611 - accuracy: 0.9595\n",
      "Epoch 17/150\n",
      "15/15 [==============================] - 0s 25ms/step - loss: 0.1532 - accuracy: 0.9392\n",
      "Epoch 18/150\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.1434 - accuracy: 0.9730\n",
      "Epoch 19/150\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.1334 - accuracy: 0.9730\n",
      "Epoch 20/150\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 0.1223 - accuracy: 0.9730\n",
      "Epoch 21/150\n",
      "15/15 [==============================] - 0s 24ms/step - loss: 0.1166 - accuracy: 0.9797\n",
      "Epoch 22/150\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.1059 - accuracy: 0.9865\n",
      "Epoch 23/150\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 0.0974 - accuracy: 0.9865\n",
      "Epoch 24/150\n",
      "15/15 [==============================] - 0s 25ms/step - loss: 0.0929 - accuracy: 0.9865\n",
      "Epoch 25/150\n",
      "15/15 [==============================] - 0s 25ms/step - loss: 0.0850 - accuracy: 0.9932\n",
      "Epoch 26/150\n",
      "15/15 [==============================] - 1s 33ms/step - loss: 0.0824 - accuracy: 0.9932\n",
      "Epoch 27/150\n",
      "15/15 [==============================] - 1s 39ms/step - loss: 0.0776 - accuracy: 0.9932\n",
      "Epoch 28/150\n",
      "15/15 [==============================] - 1s 43ms/step - loss: 0.0703 - accuracy: 0.9932\n",
      "Epoch 29/150\n",
      "15/15 [==============================] - 1s 34ms/step - loss: 0.0659 - accuracy: 0.9932\n",
      "Epoch 30/150\n",
      "15/15 [==============================] - 0s 29ms/step - loss: 0.0645 - accuracy: 0.9932\n",
      "Epoch 31/150\n",
      "15/15 [==============================] - 0s 26ms/step - loss: 0.0607 - accuracy: 0.9932\n",
      "Epoch 32/150\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 0.0554 - accuracy: 0.9932\n",
      "Epoch 33/150\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 0.0501 - accuracy: 0.9932\n",
      "Epoch 34/150\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 0.0478 - accuracy: 0.9932\n",
      "Epoch 35/150\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 0.0440 - accuracy: 0.9932\n",
      "Epoch 36/150\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 0.0417 - accuracy: 0.9932\n",
      "Epoch 37/150\n",
      "15/15 [==============================] - 0s 29ms/step - loss: 0.0390 - accuracy: 0.9932\n",
      "Epoch 38/150\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 0.0371 - accuracy: 0.9932\n",
      "Epoch 39/150\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0341 - accuracy: 0.9932\n",
      "Epoch 40/150\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 0.0319 - accuracy: 0.9932\n",
      "Epoch 41/150\n",
      "15/15 [==============================] - 0s 16ms/step - loss: 0.0303 - accuracy: 0.9932\n",
      "Epoch 42/150\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0273 - accuracy: 0.9932\n",
      "Epoch 43/150\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 0.0257 - accuracy: 0.9932\n",
      "Epoch 44/150\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0234 - accuracy: 0.9932\n",
      "Epoch 45/150\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0225 - accuracy: 1.0000\n",
      "Epoch 46/150\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0219 - accuracy: 0.9932\n",
      "Epoch 47/150\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0192 - accuracy: 1.0000\n",
      "Epoch 48/150\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0181 - accuracy: 0.9932\n",
      "Epoch 49/150\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0167 - accuracy: 1.0000\n",
      "Epoch 50/150\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0166 - accuracy: 1.0000\n",
      "Epoch 51/150\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0154 - accuracy: 0.9932\n",
      "Epoch 52/150\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0165 - accuracy: 1.0000\n",
      "Epoch 53/150\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0145 - accuracy: 0.9932\n",
      "Epoch 54/150\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0140 - accuracy: 1.0000\n",
      "Epoch 55/150\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0123 - accuracy: 1.0000\n",
      "Epoch 56/150\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0107 - accuracy: 1.0000\n",
      "Epoch 57/150\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0099 - accuracy: 1.0000\n",
      "Epoch 58/150\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0093 - accuracy: 1.0000\n",
      "Epoch 59/150\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 0.0093 - accuracy: 1.0000\n",
      "Epoch 60/150\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0086 - accuracy: 1.0000\n",
      "Epoch 61/150\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.0081 - accuracy: 1.0000\n",
      "Epoch 62/150\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.0084 - accuracy: 1.0000\n",
      "Epoch 63/150\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0083 - accuracy: 1.0000\n",
      "Epoch 64/150\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0076 - accuracy: 1.0000\n",
      "Epoch 65/150\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.0065 - accuracy: 1.0000\n",
      "Epoch 66/150\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 0.0062 - accuracy: 1.0000\n",
      "Epoch 67/150\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0058 - accuracy: 1.0000\n",
      "Epoch 68/150\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0055 - accuracy: 1.0000\n",
      "Epoch 69/150\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0053 - accuracy: 1.0000\n",
      "Epoch 70/150\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.0049 - accuracy: 1.0000\n",
      "Epoch 71/150\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0050 - accuracy: 1.0000\n",
      "Epoch 72/150\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 0.0045 - accuracy: 1.0000\n",
      "Epoch 73/150\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.0045 - accuracy: 1.0000\n",
      "Epoch 74/150\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.0042 - accuracy: 1.0000\n",
      "Epoch 75/150\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0039 - accuracy: 1.0000\n",
      "Epoch 76/150\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.0038 - accuracy: 1.0000\n",
      "Epoch 77/150\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 0.0036 - accuracy: 1.0000\n",
      "Epoch 78/150\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 0.0034 - accuracy: 1.0000\n",
      "Epoch 79/150\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.0034 - accuracy: 1.0000\n",
      "Epoch 80/150\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.0032 - accuracy: 1.0000\n",
      "Epoch 81/150\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.0031 - accuracy: 1.0000\n",
      "Epoch 82/150\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 0.0029 - accuracy: 1.0000\n",
      "Epoch 83/150\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0029 - accuracy: 1.0000\n",
      "Epoch 84/150\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 0.0028 - accuracy: 1.0000\n",
      "Epoch 85/150\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0026 - accuracy: 1.0000\n",
      "Epoch 86/150\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.0026 - accuracy: 1.0000\n",
      "Epoch 87/150\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.0024 - accuracy: 1.0000\n",
      "Epoch 88/150\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.0025 - accuracy: 1.0000\n",
      "Epoch 89/150\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 0.0023 - accuracy: 1.0000\n",
      "Epoch 90/150\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 0.0022 - accuracy: 1.0000\n",
      "Epoch 91/150\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 0.0021 - accuracy: 1.0000\n",
      "Epoch 92/150\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0020 - accuracy: 1.0000\n",
      "Epoch 93/150\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.0019 - accuracy: 1.0000\n",
      "Epoch 94/150\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.0018 - accuracy: 1.0000\n",
      "Epoch 95/150\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 0.0018 - accuracy: 1.0000\n",
      "Epoch 96/150\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 0.0019 - accuracy: 1.0000\n",
      "Epoch 97/150\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 0.0017 - accuracy: 1.0000\n",
      "Epoch 98/150\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0016 - accuracy: 1.0000\n",
      "Epoch 99/150\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0016 - accuracy: 1.0000\n",
      "Epoch 100/150\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0016 - accuracy: 1.0000\n",
      "Epoch 101/150\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0015 - accuracy: 1.0000\n",
      "Epoch 102/150\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.0014 - accuracy: 1.0000\n",
      "Epoch 103/150\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.0015 - accuracy: 1.0000\n",
      "Epoch 104/150\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0014 - accuracy: 1.0000\n",
      "Epoch 105/150\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0013 - accuracy: 1.0000\n",
      "Epoch 106/150\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.0013 - accuracy: 1.0000\n",
      "Epoch 107/150\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.0013 - accuracy: 1.0000\n",
      "Epoch 108/150\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 109/150\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 110/150\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 111/150\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 112/150\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 113/150\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 114/150\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.0010 - accuracy: 1.0000\n",
      "Epoch 115/150\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.0010 - accuracy: 1.0000\n",
      "Epoch 116/150\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 9.8333e-04 - accuracy: 1.0000\n",
      "Epoch 117/150\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 9.7745e-04 - accuracy: 1.0000\n",
      "Epoch 118/150\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 9.3442e-04 - accuracy: 1.0000\n",
      "Epoch 119/150\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 9.1806e-04 - accuracy: 1.0000\n",
      "Epoch 120/150\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 8.9832e-04 - accuracy: 1.0000\n",
      "Epoch 121/150\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 8.9578e-04 - accuracy: 1.0000\n",
      "Epoch 122/150\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 8.6492e-04 - accuracy: 1.0000\n",
      "Epoch 123/150\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 8.2717e-04 - accuracy: 1.0000\n",
      "Epoch 124/150\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 8.1228e-04 - accuracy: 1.0000\n",
      "Epoch 125/150\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 8.1183e-04 - accuracy: 1.0000\n",
      "Epoch 126/150\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 7.9671e-04 - accuracy: 1.0000\n",
      "Epoch 127/150\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 7.5780e-04 - accuracy: 1.0000\n",
      "Epoch 128/150\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 7.5345e-04 - accuracy: 1.0000\n",
      "Epoch 129/150\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 7.2428e-04 - accuracy: 1.0000\n",
      "Epoch 130/150\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 7.4006e-04 - accuracy: 1.0000\n",
      "Epoch 131/150\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 6.9556e-04 - accuracy: 1.0000\n",
      "Epoch 132/150\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 6.7554e-04 - accuracy: 1.0000\n",
      "Epoch 133/150\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 6.7114e-04 - accuracy: 1.0000\n",
      "Epoch 134/150\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 6.5128e-04 - accuracy: 1.0000\n",
      "Epoch 135/150\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 6.4624e-04 - accuracy: 1.0000\n",
      "Epoch 136/150\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 6.4606e-04 - accuracy: 1.0000\n",
      "Epoch 137/150\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 6.2062e-04 - accuracy: 1.0000\n",
      "Epoch 138/150\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 6.0149e-04 - accuracy: 1.0000\n",
      "Epoch 139/150\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 5.9143e-04 - accuracy: 1.0000\n",
      "Epoch 140/150\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 5.8218e-04 - accuracy: 1.0000\n",
      "Epoch 141/150\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 5.6972e-04 - accuracy: 1.0000\n",
      "Epoch 142/150\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 5.7863e-04 - accuracy: 1.0000\n",
      "Epoch 143/150\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 5.4310e-04 - accuracy: 1.0000\n",
      "Epoch 144/150\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 5.3365e-04 - accuracy: 1.0000\n",
      "Epoch 145/150\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 5.3038e-04 - accuracy: 1.0000\n",
      "Epoch 146/150\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 5.0677e-04 - accuracy: 1.0000\n",
      "Epoch 147/150\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 5.0767e-04 - accuracy: 1.0000\n",
      "Epoch 148/150\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 5.1062e-04 - accuracy: 1.0000\n",
      "Epoch 149/150\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 4.9068e-04 - accuracy: 1.0000\n",
      "Epoch 150/150\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 4.8062e-04 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 1s 25ms/step - loss: 1.0794 - accuracy: 0.8667\n",
      "Accuracy on testing data: 86.67\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Initialize the constructor\n",
    "model = Sequential()\n",
    "\n",
    "# Add an input layer \n",
    "model.add(Dense(64, activation='relu', input_shape=(75,)))\n",
    "\n",
    "# Add one hidden layer \n",
    "model.add(Dense(32, activation='relu'))\n",
    "\n",
    "# Add an output layer \n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "history = model.fit(X_train, y_train, epochs=150, batch_size=10, verbose=1)\n",
    "\n",
    "plt.plot(history.history['accuracy'], label='accuracy')\n",
    "plt.plot(history.history['loss'], label='training loss')\n",
    "plt.legend()\n",
    "plt.gray()\n",
    "plt.show()\n",
    "\n",
    "_, accuracy = model.evaluate(X_test, y_test)\n",
    "print('Accuracy on testing data: %.2f' % (accuracy * 100))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-06T16:15:22.232807086Z",
     "start_time": "2023-11-06T16:14:48.825505189Z"
    }
   },
   "id": "893ca021f2b77ec2"
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "outputs": [],
   "source": [
    "from keras_tuner import HyperParameters\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "import keras\n",
    "\n",
    "\n",
    "def build_model(hp):\n",
    "  model = Sequential()\n",
    "  model.add(Dense(units=hp.Int('units_0',\n",
    "                             min_value=32,\n",
    "                             max_value=512,\n",
    "                             step=32),\n",
    "                activation='relu',\n",
    "                input_dim=75))\n",
    "  for i in range(hp.Int('num_layers', 1, 7)):\n",
    "      model.add(Dense(units=hp.Int('units_' + str(i+1),\n",
    "                                min_value=32,\n",
    "                                max_value=512,\n",
    "                                step=32),\n",
    "                    activation='relu'))\n",
    "      model.add(Dropout(hp.Float('dropout_' + str(i+1),\n",
    "                                 min_value=0.0,\n",
    "                                 max_value=0.5,\n",
    "                                 step=0.1)))\n",
    "  model.add(Dense(1, activation='sigmoid'))\n",
    "  model.compile(\n",
    "      optimizer=keras.optimizers.Adam(\n",
    "          hp.Choice('learning_rate',\n",
    "                  values=[1e-2, 1e-3, 1e-4])),\n",
    "      loss='binary_crossentropy',\n",
    "      metrics=['accuracy'])\n",
    "  return model"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-06T16:31:01.655695332Z",
     "start_time": "2023-11-06T16:31:01.648960831Z"
    }
   },
   "id": "19a6ce2b4ee14cb0"
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 5 Complete [00h 00m 24s]\n",
      "val_accuracy: 0.9055555462837219\n",
      "\n",
      "Best val_accuracy So Far: 0.9388888875643412\n",
      "Total elapsed time: 00h 01m 44s\n"
     ]
    }
   ],
   "source": [
    "from keras_tuner.tuners import RandomSearch\n",
    "\n",
    "tuner = RandomSearch(\n",
    "    build_model,\n",
    "    objective='val_accuracy',\n",
    "    max_trials=5,\n",
    "    executions_per_trial=3,\n",
    "    directory='my_dir',\n",
    "    project_name='Lab 03: ECG')\n",
    "\n",
    "tuner.search(X_train, y_train,\n",
    "             epochs=150,\n",
    "             validation_data=(X_test, y_test))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4cdc1323ff11793c"
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 5ms/step - loss: 1.6962 - accuracy: 0.9500\n",
      "Test loss: 1.6961746215820312\n",
      "Test accuracy: 0.949999988079071\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.2903 - accuracy: 0.9333\n",
      "Test loss: 0.2903311848640442\n",
      "Test accuracy: 0.9333333373069763\n"
     ]
    }
   ],
   "source": [
    "models = tuner.get_best_models(num_models=2)\n",
    "\n",
    "# Evaluate the best model\n",
    "for model in models:\n",
    "    loss, accuracy = model.evaluate(X_test, y_test)\n",
    "    print('Test loss:', loss)\n",
    "    print('Test accuracy:', accuracy)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-06T16:32:58.656910156Z",
     "start_time": "2023-11-06T16:32:57.420669232Z"
    }
   },
   "id": "2fa02d801b7f1724"
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The hyperparameter search is complete. The optimal number of units in the first layer is 320, \n",
      "the optimal number of layers is 3, and the optimal learning rate is 0.01.\n"
     ]
    },
    {
     "data": {
      "text/plain": "{'_name_scopes': [],\n '_conditions': [],\n '_hps': defaultdict(list,\n             {'units_0': [Int(name: 'units_0', min_value: 32, max_value: 512, step: 32, sampling: linear, default: 32)],\n              'num_layers': [Int(name: 'num_layers', min_value: 1, max_value: 7, step: 1, sampling: linear, default: 1)],\n              'units_1': [Int(name: 'units_1', min_value: 32, max_value: 512, step: 32, sampling: linear, default: 32)],\n              'dropout_1': [Float(name: 'dropout_1', min_value: '0.0', max_value: '0.5', step: '0.1', sampling: 'linear', default: '0.0')],\n              'learning_rate': [Choice(name: 'learning_rate', values: [0.01, 0.001, 0.0001], ordered: True, default: 0.01)],\n              'units_2': [Int(name: 'units_2', min_value: 32, max_value: 512, step: 32, sampling: linear, default: 32)],\n              'dropout_2': [Float(name: 'dropout_2', min_value: '0.0', max_value: '0.5', step: '0.1', sampling: 'linear', default: '0.0')],\n              'units_3': [Int(name: 'units_3', min_value: 32, max_value: 512, step: 32, sampling: linear, default: 32)],\n              'dropout_3': [Float(name: 'dropout_3', min_value: '0.0', max_value: '0.5', step: '0.1', sampling: 'linear', default: '0.0')],\n              'units_4': [Int(name: 'units_4', min_value: 32, max_value: 512, step: 32, sampling: linear, default: 32)],\n              'dropout_4': [Float(name: 'dropout_4', min_value: '0.0', max_value: '0.5', step: '0.1', sampling: 'linear', default: '0.0')],\n              'units_5': [Int(name: 'units_5', min_value: 32, max_value: 512, step: 32, sampling: linear, default: 32)],\n              'dropout_5': [Float(name: 'dropout_5', min_value: '0.0', max_value: '0.5', step: '0.1', sampling: 'linear', default: '0.0')],\n              'units_6': [Int(name: 'units_6', min_value: 32, max_value: 512, step: 32, sampling: linear, default: 32)],\n              'dropout_6': [Float(name: 'dropout_6', min_value: '0.0', max_value: '0.5', step: '0.1', sampling: 'linear', default: '0.0')]}),\n '_space': [Int(name: 'units_0', min_value: 32, max_value: 512, step: 32, sampling: linear, default: 32),\n  Int(name: 'num_layers', min_value: 1, max_value: 7, step: 1, sampling: linear, default: 1),\n  Int(name: 'units_1', min_value: 32, max_value: 512, step: 32, sampling: linear, default: 32),\n  Float(name: 'dropout_1', min_value: '0.0', max_value: '0.5', step: '0.1', sampling: 'linear', default: '0.0'),\n  Choice(name: 'learning_rate', values: [0.01, 0.001, 0.0001], ordered: True, default: 0.01),\n  Int(name: 'units_2', min_value: 32, max_value: 512, step: 32, sampling: linear, default: 32),\n  Float(name: 'dropout_2', min_value: '0.0', max_value: '0.5', step: '0.1', sampling: 'linear', default: '0.0'),\n  Int(name: 'units_3', min_value: 32, max_value: 512, step: 32, sampling: linear, default: 32),\n  Float(name: 'dropout_3', min_value: '0.0', max_value: '0.5', step: '0.1', sampling: 'linear', default: '0.0'),\n  Int(name: 'units_4', min_value: 32, max_value: 512, step: 32, sampling: linear, default: 32),\n  Float(name: 'dropout_4', min_value: '0.0', max_value: '0.5', step: '0.1', sampling: 'linear', default: '0.0'),\n  Int(name: 'units_5', min_value: 32, max_value: 512, step: 32, sampling: linear, default: 32),\n  Float(name: 'dropout_5', min_value: '0.0', max_value: '0.5', step: '0.1', sampling: 'linear', default: '0.0'),\n  Int(name: 'units_6', min_value: 32, max_value: 512, step: 32, sampling: linear, default: 32),\n  Float(name: 'dropout_6', min_value: '0.0', max_value: '0.5', step: '0.1', sampling: 'linear', default: '0.0')],\n 'values': {'units_0': 320,\n  'num_layers': 3,\n  'units_1': 512,\n  'dropout_1': 0.30000000000000004,\n  'learning_rate': 0.01,\n  'units_2': 160,\n  'dropout_2': 0.0,\n  'units_3': 128,\n  'dropout_3': 0.0,\n  'units_4': 416,\n  'dropout_4': 0.4,\n  'units_5': 160,\n  'dropout_5': 0.30000000000000004,\n  'units_6': 512,\n  'dropout_6': 0.30000000000000004},\n 'active_scopes': [],\n 'inactive_scopes': []}"
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_hyperparameters = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "print(f\"\"\"\n",
    "The hyperparameter search is complete. The optimal number of units in the first layer is {best_hyperparameters.get('units_0')}, \n",
    "the optimal number of layers is {best_hyperparameters.get('num_layers')}, and the optimal learning rate is {best_hyperparameters.get('learning_rate')}.\n",
    "\"\"\")\n",
    "best_hyperparameters.__dict__"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-06T16:34:36.783995392Z",
     "start_time": "2023-11-06T16:34:36.734485268Z"
    }
   },
   "id": "8d6698349bb0d9ab"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "d5aaf0e49dbcb216"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
